{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ec60c07-026d-4e97-b1de-8dac2a13369e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "data=defaultdict(lambda: defaultdict(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe9ebb9-d10d-40c6-afd3-efd27b4c32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "v17=pd.read_excel(open('result_Human_eva_100ch.xlsx', 'rb'),sheet_name='Model3')\n",
    "seallm=pd.read_excel(open('result_Human_eva_100ch.xlsx', 'rb'),sheet_name='Model2')\n",
    "openthaigpt=pd.read_excel(open('result_Human_eva_100ch.xlsx', 'rb'),sheet_name='Model1')\n",
    "file=\"typhoon_polm_and_openthai_13b.xlsx\"\n",
    "typhoon=pd.read_excel(open(file, 'rb'),sheet_name='typhoon-instruct-0130')\n",
    "file=\"polm_and_openthai_13b.xlsx\"\n",
    "polylm=pd.read_excel(open(file, 'rb'),sheet_name='7b_xquad_polylmChat_ins_0shot_m')\n",
    "openthaigpt13b=pd.read_excel(open(file, 'rb'),sheet_name='7b_xquad_openthai13b_ins_0shot_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "150c00fb-f55e-469f-9cc2-97b1a37f61b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from closeai import openai # After providing your explanation, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814e1d3d-ea39-48ad-9d2c-79717df8d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import system_prompt,model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "926552ff-8890-4a28-a20e-fb9496c8e369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please evaluate these answers based on their accuracy and relevance to the provided passage that based on the Criteria:\n",
      "1. The Answer is Correct concerning the Reference Answer. Do you agree or disagree?\n",
      "Determine if the given answer accurately matches the reference answer provided. The correctness here means the answer must directly correspond to the reference answer, ensuring factual accuracy.\n",
      "2. The Answer Includes Relevant, Additional Information from the Context. Do you agree or disagree?\n",
      "Assess whether the answer provides extra details that are not only correct but also relevant and enhance the understanding of the topic as per the information given in the context.\n",
      "3. The Answer Includes Additional, Irrelevant Information from the Context. Do you agree or disagree?\n",
      "Check if the answer contains extra details that, while related to the context, do not directly pertain to the question asked. This information is not necessary for answering the question and is considered a digression.\n",
      "4. The Answer Includes Information Not Found in the Context. Do you agree or disagree?\n",
      "Evaluate if the answer includes any information that is not included in the context. This information, even if correct, is extraneous as it goes beyond the provided text and may indicate conjecture or assumption.\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b94c3a93-39c8-4c38-8766-d9fae41d466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4\n"
     ]
    }
   ],
   "source": [
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3810501c-8d41-4cd9-af7b-3db1a02f77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_bool,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ec6edb-381f-4cff-b221-9c12e07faf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bool(\"\"\"1. Is the Answer Correct concerning the Reference Answer?\n",
    "Yes, the prediction answer is correct as it matches the reference answer.\n",
    "\n",
    "2. Does the Answer Include Relevant, Additional Information from the Passage?\n",
    "Yes, the prediction answer includes relevant additional information from the passage by mentioning the names of some of the examination boards (CBSE, CISCE, NENBSE).\n",
    "\n",
    "3. Does the Answer Include Additional, Irrelevant Information from the Passage?\n",
    "No, the prediction answer does not include any irrelevant information from the passage.\n",
    "\n",
    "4. Does the Answer Include Information Not Found in the Passage?\n",
    "No, the prediction answer does not include any information that is not found in the passage.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d137e4e1-ebd2-4794-938e-e094ff74082d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ans(context, question,reference_answer, prediction_answer,show=False):\n",
    "    user_prompt=f'''Passage: {context}\n",
    "Question: {question}\n",
    "Reference Answer: \"{reference_answer}\"\n",
    "Prediction Answer: \"{prediction_answer}\"\n",
    "'''\n",
    "    if show:\n",
    "        print(user_prompt)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        n=1,\n",
    "        temperature=0.2,\n",
    "        # top_p=1,\n",
    "        # # frequency_penalty=0.0,\n",
    "        # presence_penalty=1,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3217426b-e06b-4ef4-ade8-6e0e6b303184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recheck(context, question,reference_answer, prediction_answer,show=False):\n",
    "    ok4=False\n",
    "    while ok4==False:\n",
    "        try:\n",
    "            output=get_ans(context, question,reference_answer, prediction_answer,show=show)\n",
    "            q1,q2,q3,q4=get_bool(output)\n",
    "            ok4=True\n",
    "        except:\n",
    "            ok4=False\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "809d95f2-4f7c-4cd2-859f-32280336bdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Answer is Correct concerning the Reference Answer. Do you agree or disagree?\n",
      "Agree\n",
      "2. The Answer Includes Relevant, Additional Information from the Context. Do you agree or disagree?\n",
      "Disagree\n",
      "3. The Answer Includes Additional, Irrelevant Information from the Context. Do you agree or disagree?\n",
      "Disagree\n",
      "4. The Answer Includes Information Not Found in the Context. Do you agree or disagree?\n",
      "Disagree\n"
     ]
    }
   ],
   "source": [
    "print(recheck(\n",
    "    v17[\"context\"][0],\n",
    "    v17[\"question\"][0],\n",
    "    v17[\"references\"][0],\n",
    "    v17[\"predictions\"][0],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3416f7d-d404-449e-bf45-c98de6baadd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False, False]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bool(\"\"\"1. The Answer is Correct concerning the Reference Answer. Do you agree or disagree?\n",
    "Agree\n",
    "2. The Answer Includes Relevant, Additional Information from the Context. Do you agree or disagree?\n",
    "Disagree\n",
    "3. The Answer Includes Additional, Irrelevant Information from the Context. Do you agree or disagree?\n",
    "Disagree\n",
    "4. The Answer Includes Information Not Found in the Context. Do you agree or disagree?\n",
    "Disagree\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e0da3ac-f89a-48c7-97e9-cf0152eacb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_10_data=defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ca5f687-991d-404d-b485-3342cd4946ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please evaluate these answers based on their accuracy and relevance to the provided passage that based on the Criteria:\n",
      "1. The Answer is Correct concerning the Reference Answer. Do you agree or disagree?\n",
      "Determine if the given answer accurately matches the reference answer provided. The correctness here means the answer must directly correspond to the reference answer, ensuring factual accuracy.\n",
      "2. The Answer Includes Relevant, Additional Information from the Context. Do you agree or disagree?\n",
      "Assess whether the answer provides extra details that are not only correct but also relevant and enhance the understanding of the topic as per the information given in the context.\n",
      "3. The Answer Includes Additional, Irrelevant Information from the Context. Do you agree or disagree?\n",
      "Check if the answer contains extra details that, while related to the context, do not directly pertain to the question asked. This information is not necessary for answering the question and is considered a digression.\n",
      "4. The Answer Includes Information Not Found in the Context. Do you agree or disagree?\n",
      "Evaluate if the answer includes any information that is not included in the context. This information, even if correct, is extraneous as it goes beyond the provided text and may indicate conjecture or assumption.\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcfe17b5-384f-4af4-bd8c-17cb9282289c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cc4932a41f41f8975d71460a4b81f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# first10_v17_zeros_df = v17_zeros_df.head(50)\n",
    "# first10_openthai_zeros_df = openthai_zeros_df.head(50)\n",
    "# first10_seallm_zeros_df = seallm_zeros_df.head(50)\n",
    "for i in tqdm(list(range(len(v17)))):\n",
    "    j=v17\n",
    "    first_10_data[\"v17\"].append(recheck(j[\"context\"][i],j[\"question\"][i],j[\"references\"][i],j[\"predictions\"][i]))\n",
    "    j=openthaigpt\n",
    "    first_10_data[\"openthaigpt\"].append(recheck(j[\"context\"][i],j[\"question\"][i],j[\"references\"][i],j[\"predictions\"][i]))\n",
    "    j=seallm\n",
    "    first_10_data[\"seallm\"].append(recheck(j[\"context\"][i],j[\"question\"][i],j[\"references\"][i],j[\"predictions\"][i]))\n",
    "    j=polylm\n",
    "    first_10_data[\"polylm\"].append(recheck(j[\"context\"][i],j[\"question\"][i],j[\"references\"][i],j[\"predictions\"][i]))\n",
    "    j=openthaigpt13b\n",
    "    first_10_data[\"openthaigpt13b\"].append(recheck(j[\"context\"][i],j[\"question\"][i],j[\"references\"][i],j[\"predictions\"][i]))\n",
    "    j=typhoon\n",
    "    first_10_data[\"typhoon\"].append(recheck(j[\"context\"][i],j[\"question\"][i],j[\"references\"][i],j[\"predictions\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "805e3c7c-7ac6-4c28-90a2-b4979172c0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['v17', 'openthaigpt', 'seallm', 'polylm', 'openthaigpt13b', 'typhoon'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd992f5b-9ab8-4246-a67a-216343123678",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_df=pd.DataFrame.from_dict({\n",
    "    \"context\":v17[\"context\"].to_list(),\n",
    "    \"question\":v17[\"question\"].to_list(),\n",
    "    \"references\":v17[\"references\"].to_list(),\n",
    "    # \"v17\":v17[\"predictions\"].to_list(),\n",
    "    # \"v17_gpt4\":first_10_data[\"v17\"],\n",
    "    # # \"v17_bool\":[get_bool(i) for i in first_10_data[\"v17_zeros_df\"]],\n",
    "    # \"v17_score\":[check_score_inpaper(get_bool(i)) for i in first_10_data[\"v17_zeros_df\"]],\n",
    "    # \"openthaigpt\":first10_openthai_zeros_df[\"predictions\"].to_list()[50:100],\n",
    "    # \"openthaigpt_gpt4\":first_10_data[\"openthai_zeros_df\"],\n",
    "    # # \"openthaigpt_bool\":[get_bool(i) for i in first_10_data[\"openthai_zeros_df\"]],\n",
    "    # \"openthaigpt_score\":[check_score_inpaper(get_bool(i)) for i in tqdm(first_10_data[\"openthai_zeros_df\"])],\n",
    "    # \"seallm\":first10_seallm_zeros_df[\"predictions\"].to_list()[50:100],\n",
    "    # \"seallm_gpt4\":first_10_data[\"seallm_zeros_df\"],\n",
    "    # # \"seallm_bool\":[get_bool(i) for i in first_10_data[\"seallm_zeros_df\"]],\n",
    "    # \"seallm_score\":[check_score_inpaper(get_bool(i)) for i in first_10_data[\"seallm_zeros_df\"]],\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67dba687-eb62-48a4-8433-a6236c95abc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde7e05b8b9740babdc886c280931c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5d710fcac84845b5a68eb2bda01559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eda252ea9b444c48a577999f3a63ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27b48c034be4f7ea2ce8d874bc97bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cc5108c4004272b37eade578407210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7275ea2630c44dc876178159e24ce74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in list(first_10_data.keys()):\n",
    "    l= [get_bool(i) for i in first_10_data[model]]\n",
    "    temp_df=None\n",
    "    if model == \"v17\":\n",
    "        raw_data_df[\"v17\"]=v17[\"predictions\"].to_list()\n",
    "        raw_data_df[\"v17_gpt4\"]=first_10_data[\"v17\"]\n",
    "        temp_df=v17\n",
    "    elif model == \"openthaigpt\":\n",
    "        raw_data_df[\"openthaigpt\"]=openthaigpt[\"predictions\"].to_list()\n",
    "        raw_data_df[\"openthaigpt_gpt4\"]=first_10_data[\"openthaigpt\"]\n",
    "        temp_df=openthaigpt\n",
    "    elif model == \"seallm\":\n",
    "        raw_data_df[\"seallm\"]=seallm[\"predictions\"].to_list()\n",
    "        raw_data_df[\"seallm_gpt4\"]=first_10_data[\"seallm\"]\n",
    "        temp_df=seallm\n",
    "    elif model == \"polylm\":\n",
    "        raw_data_df[\"polylm\"]=polylm[\"predictions\"].to_list()\n",
    "        raw_data_df[\"polylm_gpt4\"]=first_10_data[\"polylm\"]\n",
    "        temp_df=polylm\n",
    "    elif model == \"openthaigpt13b\":\n",
    "        raw_data_df[\"openthaigpt13b\"]=openthaigpt13b[\"predictions\"].to_list()\n",
    "        raw_data_df[\"openthaigpt13b_gpt4\"]=first_10_data[\"openthaigpt13b\"]\n",
    "        temp_df=openthaigpt13b\n",
    "    elif model == \"typhoon\":\n",
    "        raw_data_df[\"typhoon\"]=typhoon[\"predictions\"].to_list()\n",
    "        raw_data_df[\"typhoon_gpt4\"]=first_10_data[\"typhoon\"]\n",
    "        temp_df=typhoon\n",
    "    _temp = {\"q\"+str(i+1):[] for i in range(0,4)}\n",
    "    temp_bool=[get_bool(i) for i in first_10_data[model]]\n",
    "    for i in tqdm(temp_bool):\n",
    "        if i == None:\n",
    "            print(model)\n",
    "        _temp[\"q1\"].append(int(bool(i[0])))\n",
    "        _temp[\"q2\"].append(int(bool(i[1])))\n",
    "        _temp[\"q3\"].append(int(bool(i[2])))\n",
    "        _temp[\"q4\"].append(int(bool(i[3])))\n",
    "    raw_data_df[model+\"_q1\"] = _temp[\"q1\"]\n",
    "    raw_data_df[model+\"_q2\"] = _temp[\"q2\"]\n",
    "    raw_data_df[model+\"_q3\"] = _temp[\"q3\"]\n",
    "    raw_data_df[model+\"_q4\"] = _temp[\"q4\"]\n",
    "    # for q in l:\n",
    "    #     model_name = model.replace(\"_zeros_df\",\"\")\n",
    "    #     for index,ans in enumerate(q):\n",
    "    #         raw_data_df[model_name+\"_q\"+str(index+1)] = int(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00438faa-0e22-460d-af26-1f358813cc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ec46a73-a938-482d-a20b-75eacd68c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_df.to_csv(\"gpt4-100.csv\",index=False)\n",
    "raw_data_df.to_excel(\"gpt4-100.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d927f7d9-c70b-40de-ae08-38b7839266c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v17\n",
      "q1: 64\n",
      "q2: 8\n",
      "q3: 28\n",
      "q4: 5\n",
      "---------------\n",
      "openthaigpt\n",
      "q1: 58\n",
      "q2: 13\n",
      "q3: 28\n",
      "q4: 31\n",
      "---------------\n",
      "seallm\n",
      "q1: 76\n",
      "q2: 48\n",
      "q3: 32\n",
      "q4: 31\n",
      "---------------\n",
      "polylm\n",
      "q1: 73\n",
      "q2: 17\n",
      "q3: 20\n",
      "q4: 5\n",
      "---------------\n",
      "openthaigpt13b\n",
      "q1: 61\n",
      "q2: 25\n",
      "q3: 34\n",
      "q4: 38\n",
      "---------------\n",
      "typhoon\n",
      "q1: 76\n",
      "q2: 31\n",
      "q3: 25\n",
      "q4: 25\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(first_10_data.keys()):\n",
    "    print(i)\n",
    "    print(\"q1: \"+str(raw_data_df[f\"{i}_q1\"].sum()))\n",
    "    print(\"q2: \"+str(raw_data_df[f\"{i}_q2\"].sum()))\n",
    "    print(\"q3: \"+str(raw_data_df[f\"{i}_q3\"].sum()))\n",
    "    print(\"q4: \"+str(raw_data_df[f\"{i}_q4\"].sum()))\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85c9a39f-957e-498f-a1e1-72469bc24b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import word_tokenize\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d375ebc-ab57-41ad-92c5-5d44955a7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_words=defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd41ecce-01aa-42f9-97b7-3578b4bed05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v17\t5.5\n",
      "openthaigpt\t10.35\n",
      "seallm\t27.81\n",
      "polylm\t11.96\n",
      "openthaigpt13b\t17.08\n",
      "typhoon\t18.33\n"
     ]
    }
   ],
   "source": [
    "for i in list(first_10_data.keys()):\n",
    "    for j in raw_data_df[i].tolist():\n",
    "        count_words[i].append(len(word_tokenize(j,keep_whitespace=False)))\n",
    "    print(str(i)+\"\\t\"+str(sum(count_words[i])/len(count_words[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf420f-ba3b-4899-9554-9cbaf888a6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
